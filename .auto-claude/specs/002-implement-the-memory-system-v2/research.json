{
  "integrations_researched": [
    {
      "name": "Graphiti Core",
      "type": "library",
      "verified_package": {
        "name": "graphiti-core",
        "install_command": "pip install graphiti-core[falkordb]",
        "version": ">=0.24.1",
        "verified": true,
        "pypi_url": "https://pypi.org/project/graphiti-core/"
      },
      "optional_extras": {
        "falkordb": "pip install graphiti-core[falkordb]",
        "anthropic": "pip install graphiti-core[anthropic]",
        "groq": "pip install graphiti-core[groq]",
        "google_genai": "pip install graphiti-core[google-genai]",
        "multiple": "pip install graphiti-core[falkordb,anthropic,google-genai]"
      },
      "api_patterns": {
        "imports": [
          "from graphiti_core import Graphiti",
          "from graphiti_core.driver.falkordb_driver import FalkorDriver",
          "from graphiti_core.llm_client.config import LLMConfig",
          "from graphiti_core.llm_client.openai_client import OpenAIClient",
          "from graphiti_core.llm_client.anthropic_client import AnthropicClient",
          "from graphiti_core.llm_client.azure_openai_client import AzureOpenAILLMClient",
          "from graphiti_core.llm_client.openai_generic_client import OpenAIGenericClient",
          "from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig",
          "from graphiti_core.embedder.azure_openai import AzureOpenAIEmbedderClient",
          "from graphiti_core.embedder.voyage import VoyageEmbedder, VoyageAIConfig",
          "from graphiti_core.nodes import EpisodeType"
        ],
        "initialization": {
          "basic": "graphiti = Graphiti(graph_driver=driver, llm_client=llm_client, embedder=embedder)",
          "with_falkordb": "driver = FalkorDriver(host='localhost', port=6379, database='my_graph')"
        },
        "key_functions": [
          "await graphiti.build_indices_and_constraints()",
          "await graphiti.add_episode(name, episode_body, source, source_description, reference_time, group_id)",
          "await graphiti.search(query, group_ids, num_results)",
          "await graphiti.close()"
        ],
        "verified_against": "Context7 MCP: /getzep/graphiti + GitHub README"
      },
      "provider_configurations": {
        "openai_llm": {
          "client_class": "OpenAIClient",
          "config": "LLMConfig(api_key=api_key)",
          "env_var": "OPENAI_API_KEY"
        },
        "anthropic_llm": {
          "client_class": "AnthropicClient",
          "config": "LLMConfig(api_key=api_key, model='claude-sonnet-4-5-latest')",
          "env_var": "ANTHROPIC_API_KEY",
          "note": "Requires graphiti-core[anthropic] extra"
        },
        "azure_openai_llm": {
          "client_class": "AzureOpenAILLMClient",
          "config": "AzureOpenAILLMClient(azure_client=AsyncOpenAI(...), config=LLMConfig(model=deployment_name))",
          "env_vars": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_BASE_URL", "AZURE_OPENAI_LLM_DEPLOYMENT"]
        },
        "ollama_llm": {
          "client_class": "OpenAIGenericClient",
          "config": "LLMConfig(api_key='ollama', model='deepseek-r1:7b', base_url='http://localhost:11434/v1')",
          "note": "Uses OpenAI-compatible API with dummy API key"
        },
        "openai_embedder": {
          "client_class": "OpenAIEmbedder",
          "config": "OpenAIEmbedderConfig(api_key=api_key)",
          "env_var": "OPENAI_API_KEY"
        },
        "voyage_embedder": {
          "client_class": "VoyageEmbedder",
          "config": "VoyageAIConfig(api_key=api_key, embedding_model='voyage-3')",
          "env_var": "VOYAGE_API_KEY"
        },
        "azure_openai_embedder": {
          "client_class": "AzureOpenAIEmbedderClient",
          "config": "AzureOpenAIEmbedderClient(azure_client=AsyncOpenAI(...), model=embedding_deployment)",
          "env_vars": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_BASE_URL", "AZURE_OPENAI_EMBEDDING_DEPLOYMENT"]
        },
        "ollama_embedder": {
          "client_class": "OpenAIEmbedder",
          "config": "OpenAIEmbedderConfig(api_key='ollama', embedding_model='nomic-embed-text', embedding_dim=768, base_url='http://localhost:11434/v1')",
          "note": "Uses OpenAI-compatible API with dummy API key"
        }
      },
      "gotchas": [
        "Must call build_indices_and_constraints() before first use",
        "Requires OpenAI API key by default for embeddings (unless using alternative provider)",
        "FalkorDB uses port 6379 by default (not 6380 as in some docs)",
        "Ollama requires placeholder API key 'ollama' even though it's not used",
        "Anthropic does NOT provide embeddings - must pair with OpenAI, Voyage, or Ollama embedder",
        "Azure OpenAI requires /openai/v1/ suffix on base URL"
      ],
      "research_sources": [
        "https://pypi.org/project/graphiti-core/",
        "https://github.com/getzep/graphiti",
        "Context7 MCP: /getzep/graphiti"
      ]
    },
    {
      "name": "FalkorDB",
      "type": "infrastructure",
      "verified_package": {
        "name": "falkordb",
        "install_command": "pip install falkordb",
        "version": ">=1.2.2",
        "verified": true,
        "pypi_url": "https://pypi.org/project/FalkorDB/"
      },
      "api_patterns": {
        "imports": [
          "from falkordb import FalkorDB",
          "from graphiti_core.driver.falkordb_driver import FalkorDriver"
        ],
        "initialization": "FalkorDriver(host='localhost', port=6379, database='my_knowledge_graph')",
        "key_functions": [
          "db.select_graph(name)",
          "g.query(cypher_query)"
        ],
        "verified_against": "Context7 MCP: /websites/falkordb + FalkorDB docs"
      },
      "configuration": {
        "env_vars": [
          "GRAPHITI_FALKORDB_HOST",
          "GRAPHITI_FALKORDB_PORT",
          "GRAPHITI_FALKORDB_PASSWORD"
        ],
        "default_host": "localhost",
        "default_port": 6379,
        "docker_port_mapping": "6379:6379"
      },
      "infrastructure": {
        "requires_docker": true,
        "docker_image": "falkordb/falkordb:latest",
        "docker_run": "docker run --rm -p 6379:6379 falkordb/falkordb",
        "ports": [6379],
        "volumes": []
      },
      "gotchas": [
        "Default port is 6379 (Redis protocol), NOT 6380",
        "Graphiti config currently uses port 6380 - may need adjustment",
        "FalkorDB uses Redis protocol (bolt:// connection string pattern)",
        "Requires Python >=3.8 and <4.0"
      ],
      "research_sources": [
        "https://pypi.org/project/FalkorDB/",
        "https://docs.falkordb.com/getting-started/",
        "https://github.com/FalkorDB/falkordb-py"
      ]
    },
    {
      "name": "Anthropic SDK (LLM Provider)",
      "type": "library",
      "verified_package": {
        "name": "anthropic",
        "install_command": "pip install anthropic",
        "version": "latest",
        "verified": true,
        "pypi_url": "https://pypi.org/project/anthropic/"
      },
      "api_patterns": {
        "imports": [
          "from anthropic import Anthropic, AsyncAnthropic"
        ],
        "initialization": "client = Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))",
        "key_functions": [
          "client.messages.create(max_tokens, messages, model)",
          "await async_client.messages.create(...)"
        ],
        "graphiti_integration": {
          "import": "from graphiti_core.llm_client.anthropic_client import AnthropicClient",
          "usage": "llm_client = AnthropicClient(config=LLMConfig(api_key=api_key, model='claude-sonnet-4-5-latest'))"
        },
        "verified_against": "Context7 MCP: /anthropics/anthropic-sdk-python"
      },
      "configuration": {
        "env_vars": ["ANTHROPIC_API_KEY"],
        "models": ["claude-sonnet-4-5-latest", "claude-opus-4-5-latest", "claude-haiku-3-5-latest"]
      },
      "gotchas": [
        "Anthropic does NOT provide embedding models",
        "Must pair with another provider for embeddings (Voyage AI recommended by Anthropic)",
        "Requires graphiti-core[anthropic] extra for Graphiti integration"
      ],
      "research_sources": [
        "https://github.com/anthropics/anthropic-sdk-python",
        "Context7 MCP: /anthropics/anthropic-sdk-python"
      ]
    },
    {
      "name": "Voyage AI (Embeddings Provider)",
      "type": "service",
      "verified_package": {
        "name": "voyageai",
        "install_command": "pip install voyageai",
        "version": "latest",
        "verified": true,
        "pypi_url": "https://pypi.org/project/voyageai/"
      },
      "api_patterns": {
        "imports": [
          "import voyageai"
        ],
        "initialization": "vo = voyageai.Client()  # Uses VOYAGE_API_KEY env var",
        "key_functions": [
          "vo.embed(texts, model, input_type)",
          "vo.multimodal_embed(inputs, model)"
        ],
        "graphiti_integration": {
          "import": "from graphiti_core.embedder.voyage import VoyageEmbedder, VoyageAIConfig",
          "usage": "embedder = VoyageEmbedder(config=VoyageAIConfig(api_key=api_key, embedding_model='voyage-3'))"
        },
        "verified_against": "Context7 MCP: /websites/voyageai + voyageai docs"
      },
      "configuration": {
        "env_vars": ["VOYAGE_API_KEY"],
        "models": {
          "voyage-3": {"dimensions": 1024, "use_case": "general"},
          "voyage-3-lite": {"dimensions": 512, "use_case": "lightweight"},
          "voyage-3.5": {"dimensions": 1024, "use_case": "latest general"},
          "voyage-3.5-lite": {"dimensions": 512, "use_case": "latest lightweight"},
          "voyage-code-3": {"dimensions": 1024, "use_case": "code"},
          "voyage-finance-2": {"dimensions": 1024, "use_case": "finance"}
        }
      },
      "gotchas": [
        "Embedding dimensions vary by model (512-1024)",
        "API rate limits apply - check pricing tier",
        "Recommended by Anthropic as their embedding partner",
        "Supports input_type='query' vs 'document' for retrieval optimization"
      ],
      "research_sources": [
        "https://pypi.org/project/voyageai/",
        "https://docs.voyageai.com/docs/embeddings",
        "https://github.com/voyage-ai/voyageai-python"
      ]
    },
    {
      "name": "Ollama (Local LLM/Embeddings)",
      "type": "infrastructure",
      "verified_package": {
        "name": "ollama",
        "install_command": "pip install ollama",
        "version": "latest",
        "verified": true,
        "pypi_url": "https://pypi.org/project/ollama/"
      },
      "api_patterns": {
        "imports": [
          "import ollama",
          "from ollama import embed, EmbedResponse"
        ],
        "initialization": "No client initialization needed - uses localhost:11434 by default",
        "key_functions": [
          "ollama.embed(model, input)",
          "ollama.chat(model, messages)",
          "ollama.generate(model, prompt)"
        ],
        "openai_compatible_api": {
          "base_url": "http://localhost:11434/v1",
          "api_key": "ollama",
          "note": "Fully OpenAI-compatible API for LLM and embeddings"
        },
        "graphiti_integration": {
          "llm": "OpenAIGenericClient(config=LLMConfig(api_key='ollama', model='deepseek-r1:7b', base_url='http://localhost:11434/v1'))",
          "embedder": "OpenAIEmbedder(config=OpenAIEmbedderConfig(api_key='ollama', embedding_model='nomic-embed-text', embedding_dim=768, base_url='http://localhost:11434/v1'))"
        },
        "verified_against": "Context7 MCP: /ollama/ollama-python + /websites/ollama"
      },
      "configuration": {
        "env_vars": [
          "OLLAMA_BASE_URL",
          "OLLAMA_LLM_MODEL",
          "OLLAMA_EMBEDDING_MODEL",
          "OLLAMA_EMBEDDING_DIM"
        ],
        "default_base_url": "http://localhost:11434/v1",
        "recommended_models": {
          "llm": ["deepseek-r1:7b", "llama3:8b", "mistral:7b", "qwen2:7b"],
          "embeddings": ["nomic-embed-text", "mxbai-embed-large", "all-minilm"]
        },
        "embedding_dimensions": {
          "nomic-embed-text": 768,
          "mxbai-embed-large": 1024,
          "all-minilm": 384
        }
      },
      "infrastructure": {
        "requires_docker": false,
        "install_command": "curl -fsSL https://ollama.com/install.sh | sh",
        "pull_models": [
          "ollama pull deepseek-r1:7b",
          "ollama pull nomic-embed-text"
        ],
        "service_command": "ollama serve",
        "ports": [11434]
      },
      "gotchas": [
        "Requires local GPU for good performance with larger models",
        "Embedding quality may be lower than cloud providers (OpenAI/Voyage)",
        "Must pull models before use with 'ollama pull <model>'",
        "Uses placeholder API key 'ollama' for OpenAI-compatible API",
        "Embedding dimension must match model - mismatch causes errors",
        "Service must be running before Graphiti initialization"
      ],
      "research_sources": [
        "https://docs.ollama.com/api/openai-compatibility",
        "https://github.com/ollama/ollama-python",
        "Context7 MCP: /ollama/ollama-python"
      ]
    },
    {
      "name": "Azure OpenAI",
      "type": "service",
      "verified_package": {
        "name": "openai",
        "install_command": "pip install openai",
        "version": "latest",
        "verified": true,
        "note": "Uses standard OpenAI SDK with Azure endpoints"
      },
      "api_patterns": {
        "imports": [
          "from openai import AsyncOpenAI",
          "from graphiti_core.llm_client.azure_openai_client import AzureOpenAILLMClient",
          "from graphiti_core.embedder.azure_openai import AzureOpenAIEmbedderClient"
        ],
        "initialization": "azure_client = AsyncOpenAI(base_url='https://your-resource.openai.azure.com/openai/v1/', api_key=api_key)",
        "graphiti_integration": {
          "llm": "AzureOpenAILLMClient(azure_client=azure_client, config=LLMConfig(model=deployment_name, small_model=deployment_name))",
          "embedder": "AzureOpenAIEmbedderClient(azure_client=azure_client, model=embedding_deployment)"
        },
        "verified_against": "Context7 MCP: /getzep/graphiti (Azure OpenAI examples)"
      },
      "configuration": {
        "env_vars": [
          "AZURE_OPENAI_API_KEY",
          "AZURE_OPENAI_BASE_URL",
          "AZURE_OPENAI_LLM_DEPLOYMENT",
          "AZURE_OPENAI_EMBEDDING_DEPLOYMENT"
        ],
        "base_url_format": "https://{resource-name}.openai.azure.com/openai/v1/",
        "deployment_models": {
          "llm": ["gpt-4o", "gpt-4", "gpt-35-turbo"],
          "embeddings": ["text-embedding-3-small", "text-embedding-3-large", "text-embedding-ada-002"]
        }
      },
      "gotchas": [
        "Base URL must end with /openai/v1/",
        "Uses deployment names, not model names",
        "Requires Azure subscription and resource setup",
        "API version handling is automatic with v1 endpoint",
        "Enterprise compliance and data residency requirements met"
      ],
      "research_sources": [
        "https://github.com/getzep/graphiti/blob/main/examples/azure-openai/",
        "Context7 MCP: /getzep/graphiti"
      ]
    },
    {
      "name": "OpenAI (Default Provider)",
      "type": "service",
      "verified_package": {
        "name": "openai",
        "install_command": "pip install openai",
        "version": "latest",
        "verified": true,
        "pypi_url": "https://pypi.org/project/openai/"
      },
      "api_patterns": {
        "imports": [
          "from graphiti_core.llm_client.openai_client import OpenAIClient",
          "from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig"
        ],
        "graphiti_integration": {
          "llm": "OpenAIClient(config=LLMConfig(api_key=api_key))",
          "embedder": "OpenAIEmbedder(config=OpenAIEmbedderConfig(api_key=api_key))"
        },
        "verified_against": "Context7 MCP: /getzep/graphiti"
      },
      "configuration": {
        "env_vars": ["OPENAI_API_KEY"],
        "models": {
          "llm": ["gpt-4o", "gpt-4-turbo", "gpt-4"],
          "embeddings": ["text-embedding-3-small", "text-embedding-3-large"]
        },
        "embedding_dimensions": {
          "text-embedding-3-small": 1536,
          "text-embedding-3-large": 3072
        }
      },
      "gotchas": [
        "Default provider for Graphiti - simplest setup",
        "API costs apply for all requests",
        "Rate limits depend on account tier"
      ],
      "research_sources": [
        "https://github.com/getzep/graphiti",
        "Context7 MCP: /getzep/graphiti"
      ]
    }
  ],
  "unverified_claims": [
    {
      "claim": "Graphiti uses port 6380 for FalkorDB by default",
      "reason": "FalkorDB documentation shows port 6379 as default, but existing graphiti_config.py uses 6380. Need to verify which is correct for this project.",
      "risk_level": "low",
      "recommendation": "Check docker-compose.yml for actual port mapping in use"
    }
  ],
  "provider_combinations": {
    "default": {
      "llm": "OpenAI",
      "embedder": "OpenAI",
      "use_case": "Simple setup, good quality",
      "cost": "$$"
    },
    "enterprise": {
      "llm": "Azure OpenAI",
      "embedder": "Azure OpenAI",
      "use_case": "Corporate compliance, data residency",
      "cost": "$$"
    },
    "claude_stack": {
      "llm": "Anthropic",
      "embedder": "Voyage AI",
      "use_case": "Consistency with Claude agents, Anthropic's recommendation",
      "cost": "$$"
    },
    "fully_local": {
      "llm": "Ollama",
      "embedder": "Ollama",
      "use_case": "Privacy, offline, zero API costs",
      "cost": "Free"
    },
    "hybrid_local": {
      "llm": "Ollama",
      "embedder": "OpenAI",
      "use_case": "Local LLM, quality embeddings",
      "cost": "$"
    },
    "cost_optimized": {
      "llm": "Anthropic",
      "embedder": "Ollama",
      "use_case": "Cloud LLM quality, free embeddings",
      "cost": "$"
    }
  },
  "embedding_dimensions_by_provider": {
    "openai": {
      "text-embedding-3-small": 1536,
      "text-embedding-3-large": 3072
    },
    "voyage": {
      "voyage-3": 1024,
      "voyage-3-lite": 512,
      "voyage-3.5": 1024,
      "voyage-3.5-lite": 512
    },
    "ollama": {
      "nomic-embed-text": 768,
      "mxbai-embed-large": 1024,
      "all-minilm": 384
    }
  },
  "environment_variables_summary": {
    "core": [
      "GRAPHITI_ENABLED=true",
      "GRAPHITI_LLM_PROVIDER=openai|azure_openai|anthropic|ollama",
      "GRAPHITI_EMBEDDER_PROVIDER=openai|azure_openai|voyage|ollama"
    ],
    "openai": ["OPENAI_API_KEY"],
    "anthropic": ["ANTHROPIC_API_KEY", "GRAPHITI_ANTHROPIC_MODEL"],
    "azure_openai": [
      "AZURE_OPENAI_API_KEY",
      "AZURE_OPENAI_BASE_URL",
      "AZURE_OPENAI_LLM_DEPLOYMENT",
      "AZURE_OPENAI_EMBEDDING_DEPLOYMENT"
    ],
    "ollama": [
      "OLLAMA_BASE_URL",
      "OLLAMA_LLM_MODEL",
      "OLLAMA_EMBEDDING_MODEL",
      "OLLAMA_EMBEDDING_DIM"
    ],
    "voyage": ["VOYAGE_API_KEY", "VOYAGE_EMBEDDING_MODEL"],
    "falkordb": [
      "GRAPHITI_FALKORDB_HOST",
      "GRAPHITI_FALKORDB_PORT",
      "GRAPHITI_FALKORDB_PASSWORD",
      "GRAPHITI_DATABASE"
    ]
  },
  "recommendations": [
    "Use graphiti-core[falkordb] for FalkorDB integration - it's the recommended graph database",
    "For Anthropic LLM users, pair with Voyage AI embeddings (Anthropic's official recommendation)",
    "Ollama provides a zero-cost local option but requires pulling models first",
    "Azure OpenAI requires /openai/v1/ suffix on base URL - common mistake to omit this",
    "Embedding dimensions must match across the system - mixing dimensions causes errors",
    "Test provider combinations before deployment - not all combinations are officially tested",
    "Consider fallback to file-based memory when Graphiti providers are unavailable"
  ],
  "context7_libraries_used": [
    "/getzep/graphiti",
    "/websites/falkordb",
    "/websites/voyageai",
    "/ollama/ollama-python",
    "/anthropics/anthropic-sdk-python",
    "/websites/ollama"
  ],
  "created_at": "2025-12-12T11:30:00Z"
}
